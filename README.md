# CSE 455 Birds Kaggle Competition Spring 2023!

## Introduction

I really wanted to explore a new direction of computer vision outside of what we learned in class for this final project, but I couldn't find a group and wasn't ready to commit to an idea when project proposals were due. However, I really enjoyed participating in this Kaggle competetion as well! This README will serve as my deliverable website which covers this project's problem description, previous work used, my approach, datasets used, my results, and some discussion regarding the overall project.

![c71-2](https://github.com/alexzhanguw/cse455-birds/assets/135690578/89a5f628-11c7-43b4-8474-0aea38669203)

## Problem Description

I competed in the default final project. This final project was [a bird classification Kaggle competition](https://www.kaggle.com/competitions/birds23sp/overview), where the class was working with a provided dataset, consisting of 38,562 bird images in different training data input files and their corresponding species labels, with the goal of training a model that could accurately produce a predictions file for a provided test file containing unseen bird images. To be more specific, there were 555 given bird species, and our predictions file was aiming to achieve the highest accuracy in tagging each image in the test file to its corresponding label among the 555 given bird species. Our results were shown against our fellow classmates on the Kaggle competition leaderboard.

![Warbler-speciess-1080x675](https://github.com/alexzhanguw/cse455-birds/assets/135690578/15c6b304-ae73-47cc-be21-1d3e9135e1bc)

## Previous Work

As a starting point, I used code from the transfer learning notebooks provided on the course website: I mainly used [this notebook](https://colab.research.google.com/drive/1kHo8VT-onDxbtS3FM77VImG35h_K_Lav?usp=sharing) as a baseline and took parts such as testing for accuracy from [this notebook](https://colab.research.google.com/drive/1EBz4feoaUvz-o_yeMI27LEQBkvrXNc_4?usp=sharing). Specifically, from the first notebook, I closely followed the data augmentation and dataloader generation. However, I changed and tried out my own data augmentations and also split the training data set into a training set and validation set with a 90/10 split, which caused a deviation in how I was generating the dataloaders. I also followed the training function closely, but I added an option to used the Adam optimizer instead of the provided optimizer parameters and an accuracy check at the end of each epoch to gauge whether I wanted to commit to a training run or not. There was also a seeding block that I followed; I found it very interesting to see how seeding can affect models and its effects in Kaggle competitions. [This](https://wandb.ai/sauravmaheshkar/RSNA-MICCAI/reports/How-to-Set-Random-Seeds-in-PyTorch-and-Tensorflow--VmlldzoxMDA2MDQy) is the website where I found this information. Seeding also allowed me to get determinstic runs, which helped me save some time when training.

![merb10108262035](https://github.com/alexzhanguw/cse455-birds/assets/135690578/4d57f716-94c9-45a6-874d-4d416f27a904)

## My Approach

When I first started this project, I was a bit overwhelmed by what to do. This was also my first Kaggle competetion so getting started was a bit daunting. From lectures, I knew that I wanted to try out a pretrained model and apply transfer learning to these to make my predictions. Since there was a provided notebook which did exactly that on the course website, I decided to use it as a baseline. I first made sure to understand what the notebook was doing and then looked into the provided data and made sure to understand what each folder in the input data was meant for. My intial approach was to try hyperparameter tuning. I used a grid search with the transfer learning to birds notebook mentioned above, now adjusted to use the Kaggle dataset, searching over epochs, learning rate, momentum, decay, and data augmentation parameters. Unfortunately, this was not very successful and ended up burning significant GPU time. This was frustrating, and I ended up deleting this original notebook so I no longer have my original attmept's results, but I think my validation accuracy ended at round 65%. I made a validation split from the original training set to better gauge my progress, this also made the training a tiny bit faster since there was less data in the training set. I next tried to switch the optimizer to Adam, but this also did not help much. I also tried to bring in a [new bird dataset](https://www.kaggle.com/datasets/gpiosenka/100-bird-species) but could not maatch the species and labels between the datasets since some were missing, so I gave up on integrating the new dataset. My first significant progress was from looking more into data augmentation. Data augmentation allows "new" training data to be generated. This creates a larger dataset to train with. Data augmentation has also have been shown to prevent overfitting in models while still being able to increase their accuracy. Specifically, I added a new data agumentation for my data to be resized and cropped, horizontally flipped, rotated, "color jittered," and normalized by the [PyTorch ImageNet standard](https://github.com/pytorch/examples/blob/main/imagenet/main.py#L209-L214). This allowed me to achieve a validation score of above 70 on my validation accuracy. With this progress, I decided that I would try starting to train for a series of epochs with the larger data augmentation provided in the baseline transfer learning to birds notebook, and then switching to the new data augmentation and training the same previously trained model with this new data augmentation for another series of epochs. I finally added another data augmentation on top of this and then trained the same model with the final augmented dataset. The difference between the second and final data augmentation was the parameters for the scaling transformation. I also increased the number of epochs, reduced learning rates as epochs increased, and increased decay as epochs increased to reduce overfitting and get better results. I also added seeding as stated above. With these results, I was able to reach over 80% on my validation accuracy.

![new-study-changes-thinking-on-evolution-of-flightless-birds-650x432](https://github.com/alexzhanguw/cse455-birds/assets/135690578/60649b73-a350-4298-909e-f97525aeb3eb)

## Datasets

For this competetion, I only used the provided [dataset](https://www.kaggle.com/competitions/birds23sp/data). As stated above, I tried to bring in another bird classification dataset from Kaggle, but their setups were different, and it would be difficult to have the other dataset map the same as the provided dataset. Thus, I did not bring in this dataset, but in the future, I would like to try harder to incorporate this data file along with the provided dataset. In the provided dataset, there is a test folder, which consists of many bird images, which have no given corresponding label; a train folder, which consists of 555 folders, each with multiple images of birds of the same species; a labels file, containing the correct mapping of training images to their labels; a names file, containing the names of all the species bird species provided in the training set; and finally a sample file, which is a sample predictions file.

![26tb-cockatoos-02-superJumbo](https://github.com/alexzhanguw/cse455-birds/assets/135690578/34dd4da0-e923-443c-afbf-0446ea6b4f1b)

## Results

For my best results, I recieved an evaluation score of 0.79700 for the public Kaggle score. On multiple runs, I have achieved traning accuracy of 99% and have reached in the high 80% for my validation accuracy on multiple runs as well. In my most recent run, my training accuracy was 0.991673 while my validation accuracy was 0.886959. My ending loss was 0.212, though I had lower losses during training.

![6470ee02085acb0018feaf1a](https://github.com/alexzhanguw/cse455-birds/assets/135690578/d5c78d09-d47b-422d-be7b-474bc3226538)

## Discussion

My first problem I encountered was trying to bring in new datasets, since the provided dataset was provided in a specific format. Like I mentioned above, this made it difficult to trying have format the new datasets to match the provided dataset. Another problem I faced was trying to have checkpoint .pkl files persist in a folder I created in the working directory of the notebook. I wanted to use this files to save me time in training by being able to start from the model at a previously trained epoch. I spent a non-trivial amount of time trying to solve this issue, but in the end, I used seeding to make my result determinisitc, and I also realized that I would be training in a single run, so I didnt need to have my checkpoint .pkl files to persist after a run. If I was to keep working on this project, I would spend more time trying to bring in the dataset I have mentioned. I feel that providing new data to my model could increase my accuracy, since I am currently training for above 15 total epochs, which increases the chance of overfitting. With new and more data, I feel that I could decrease the number of epochs, while still being able to achieve better accuracy. Another step I would take is to explore different pretrained models, such as ResNet models apart from ResNet18, EffecientNet, or VGG19. I was not able to do so this time, because I was commited mostly to ResNet18, and began briefly experimenting with ResNet50. Unfortunately, I ran out of GPU quota in Kaggle, so this exploration was shortlived. At that point, I decided that I should just use what I have already done and that my laptop (which sounded like it was going to bimplode on multiple occasions) should have a rest. In the future, I still think it would be interesting to compare the results of different pretrained models though. In the end, the main novelty of my approach, on top of hyperparameter tuning and seeding, was adding multiple training layers, each with different data augmentations. I believe that it was beneficial, since this approach produced my best results and was better compared to when I stuck with one of the single data augmentations I had used, trained on the same number of overall epochs. Ultimately, I think that I completed the task/problem/challenge to satisfactory extent, as I have achieved a score of near 80% for the Kaggle competetion.

I have included [my Kaggle notebook](https://github.com/alexzhanguw/cse455-birds/blob/main/birds.ipynb) in this repo for reference.

![360_F_419845144_4O5PeH7pjeGXu5sL1T9OKk5LEOeiZikU](https://github.com/alexzhanguw/cse455-birds/assets/135690578/ae6577e0-cda1-4a91-a7c3-c8bec24558ce)
